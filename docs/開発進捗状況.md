# 開発進捗状況

## 開発進捗

### ✅ 完了済み
- **DB設計**: `docs/DB設計.md` に基づくスキーマ設計完了
- **Supabase接続**: 基本的な接続設定とテーブル作成完了
- **データ移行**: タノメール製品データのSupabase移行完了
- **Embedding生成**: Azure OpenAI text-embedding-3-large による埋め込み生成スクリプト実装
- **チケットA-1**: Supabase API/接続情報の確認完了
- **チケットA-2**: Difyの「SQL Database」ツール接続完了
- **チケットB-1**: pgvector拡張とスキーマ準備完了
- **チケットB-2**: 既存データへの埋め込みバックフィル完了
- **チケットB-3**: Supabase Edge Function で `/retrieval` 実装
- **チケットA-3**: DifyフローにSQL実行ノード追加
- **チケットA-4**: 動作確認と簡易プロンプト整形
- **チケットB-4**: Edge Functionのデプロイとシークレット設定
- **チケットB-5**: Difyに「外部ナレッジAPI」登録
- **チケットB-6**: 外部ナレッジベース作成とアプリ利用

### ⏳ 未完了
- **データセットの充実(特にproductsテーブル)**
- **productsテーブルに行が挿入されるイベントをトリガーにproducts.discriptionに対するpgvector生成のための関数作成**

## 現時点で出来上がっている機能

### 1. データベース基盤
- **Supabase接続**: PostgreSQLベースのクラウドDB
- **テーブル構造**: 11個のテーブル (商談管理、製品カタログ、顧客情報の基本テーブル)
- **製品データ**: 413件の製品情報（name, cost, category, brand, description）

### 2. 埋め込み検索基盤
- **pgvector拡張**: ベクトル検索用拡張機能
- **埋め込み生成**: Azure OpenAI text-embedding-3-large による3072次元ベクトル
- **検索RPC**: `match_products` 関数による類似度検索

### 3. データ移行・管理ツール
- **製品データ移行**: CSV → Supabase 自動移行スクリプト
- **埋め込み生成**: バッチ処理による埋め込み生成

### 4. 開発環境
- **Docker環境**: Streamlit + uv + Docker 構成
- **環境変数管理**: Azure OpenAI、Supabase接続情報
- **Python環境**: 必要なライブラリ（supabase-py, openai等）

## 困ったこと

### 1. Edge FunctionのDifyへの連携
- **Difyへの連携**: Difyのエージェントノード内でEdge functionを呼び出そうとすると、リクエスト要素の型がobject設定にしているはずが、string扱いになり、エラーとなる
    -  **解決**: Difyのフローを変更することで解決:
        - 具体的にはエージェントノードに渡す前にEdge functionを単体で呼び出す「知識検索ノード」を設置することで解決

### 2. embedding作成時のインデックス生成
- **pgvectorの仕様**: `embedding fullvec(3072)` カラム、HNSWインデックス 指定すると、`fullvector` に対して HNSW は 2000 次元上限であったため、エラー
    - **解決**: `embedding halfvec(3072)` カラム、HNSWインデックス（pgvector ≥ 0.7）のように **halfvec**を指定することで次元上限を4000に緩和させ、解決
        - 注意: `halfvec`（16-bit 浮動小数）と HNSW の 4000 次元上限は pgvector 0.7 以降で有効

### 3. 技術的な課題
- **ベクトル検索精度**: 適切な `score_threshold` の設定
    - **一時的解決**: `score_threshold`で表示件数が0件の場合は`score_threshold = 0`にして、再度`top_k`条件のみで検索をかけることで確実に何かしらの検索結果を得る